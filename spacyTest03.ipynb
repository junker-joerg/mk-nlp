{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load('de_core_news_sm')\n",
    "nlp = spacy.load('de_core_news_md')\n",
    "doc = nlp(u'Ich bin ein Berliner.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(u'Der Apfel und die Orange sind ähnlich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27352026"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "der_apfel = doc[:2]\n",
    "die_orange = doc[3:5]\n",
    "der_apfel.similarity(die_orange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Den Berliner hat der Hund nicht gebissen.')\n",
    "# heads array: [1, 6, 2, 4, 2, 6, 2, 2] (second token is attached with a non-projective arc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Den/DET Berliner/NOUN hat/AUX der/DET Hund/NOUN nicht/PART gebissen/VERB ./PUNCT\n"
     ]
    }
   ],
   "source": [
    "print(' '.join('{word}/{tag}'.format(word=t.orth_, tag=t.pos_) for t in doc))\n",
    "# output: Ich/PRON bin/AUX ein/DET Berliner/NOUN ./PUNCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Den      <--nk--- Berliner\n",
      "Berliner <--oa--- gebissen\n",
      "hat      <-ROOT-- hat\n",
      "der      <--nk--- Hund\n",
      "Hund     <--sb--- hat\n",
      "nicht    <--ng--- gebissen\n",
      "gebissen <--oc--- hat\n",
      ".        <-punct- hat\n"
     ]
    }
   ],
   "source": [
    "# show dependency arcs\n",
    "print('\\n'.join('{child:<8} <{label:-^7} {head}'.format(child=t.orth_, label=t.dep_, head=t.head.orth_) for t in doc))\n",
    "# output: (sb: subject, nk: noun kernel, pd: predicate)\n",
    "# Ich      <--sb--- bin\n",
    "# bin      <-ROOT-- bin\n",
    "# ein      <--nk--- Berliner\n",
    "# Berliner <--pd--- bin\n",
    "# .        <-punct- bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berliner\n"
     ]
    }
   ],
   "source": [
    "# show named entities\n",
    "for ent in doc.ents:\n",
    "    print(ent.text)\n",
    "# output:\n",
    "# Berline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Den Berliner\n",
      "der Hund\n",
      "[Ich, Essen, eine Tasse, Kaffee]\n",
      "[Der Senator, das Thema Flughafen]\n"
     ]
    }
   ],
   "source": [
    "# show noun chunks\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)\n",
    "# output:\n",
    "# ein Berliner\n",
    "\n",
    "# noun chunks include so-called measure constructions ...\n",
    "doc = nlp(u'Ich möchte gern zum Essen eine Tasse Kaffee bestellen.')\n",
    "print( [ chunk for chunk in doc.noun_chunks ])\n",
    "# output:\n",
    "# [Essen, eine Tasse Kaffee]\n",
    "\n",
    "# ... and close appositions\n",
    "doc = nlp(u'Der Senator vermeidet das Thema Flughafen.')\n",
    "print( [ chunk for chunk in doc.noun_chunks ])\n",
    "# output:\n",
    "# [Der Senator, das Thema Flughafen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36658847"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use word vectors\n",
    "#de = spacy.load('de')\n",
    "doc = nlp(u'Der Apfel und die Orange sind ähnlich')\n",
    "assert len(doc.vector) == len(doc[0].vector)\n",
    "der_apfel = doc[:2]\n",
    "die_orange = doc[3:5]\n",
    "der_apfel.similarity(die_orange)\n",
    "# output:\n",
    "# 0.63665210991205579\n",
    "der, apfel = der_apfel\n",
    "der.similarity(apfel)\n",
    "# output:\n",
    "# 0.24995991403916812"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2 und\n"
     ]
    }
   ],
   "source": [
    "# the root has no left dependents:\n",
    "print(doc[2].n_lefts)\n",
    "# output:\n",
    "# 0\n",
    "\n",
    "# but the root's left-most descendant is not the root itself but a token further left\n",
    "print(doc[2].left_edge.i, doc[2].left_edge.orth_)\n",
    "# output:\n",
    "# (0, u'Den')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chartbeat-labs.github.io/textacy/getting_started/quickstart.html#working-with-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
